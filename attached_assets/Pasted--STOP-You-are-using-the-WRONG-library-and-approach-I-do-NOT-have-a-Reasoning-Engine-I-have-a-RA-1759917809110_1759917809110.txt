
STOP - You are using the WRONG library and approach!

I do NOT have a Reasoning Engine. I have a RAG Corpus with the google-genai SDK.

CRITICAL REQUIREMENTS:
1. Install ONLY this package: pip install google-genai
2. Do NOT use google-cloud-aiplatform
3. Do NOT search for "Reasoning Engine"
4. My VERTEX_AI_AGENT_ID is a RAG CORPUS (not a Reasoning Engine)

My 4 secrets are:
- GOOGLE_CLOUD_PROJECT = uzb-agent
- VERTEX_AI_LOCATION = europe-west4
- VERTEX_AI_AGENT_ID = projects/uzb-agent/locations/europe-west4/ragCorpora/3458764513820540928
- GOOGLE_APPLICATION_CREDENTIALS = {service account JSON}

Create backend/services/vertex_ai_service.py with this EXACT code:
```python
from google import genai
from google.genai import types
import os
import json

class VertexAIService:
    def __init__(self):
        # Load service account credentials
        credentials_json = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
        
        # Parse JSON if it's a string
        if isinstance(credentials_json, str):
            credentials = json.loads(credentials_json)
        else:
            credentials = credentials_json
        
        # Initialize Vertex AI client
        self.client = genai.Client(
            vertexai=True,
            project=os.environ.get("GOOGLE_CLOUD_PROJECT"),
            location=os.environ.get("VERTEX_AI_LOCATION"),
        )
        
        self.model = "gemini-2.5-pro"
        self.rag_corpus = os.environ.get("VERTEX_AI_AGENT_ID")
        
        self.system_instruction = """Je bent Lex - Expert Loonadministrateur voor UZB (NBBU CAO).

KERN INSTRUCTIES:
- Gebruik je volledige kennisbank om de beste antwoorden te geven
- UZB hanteert NBBU CAO als standaard
- Geef concrete, bruikbare adviezen
- Wees transparant over bronnen

KRITIEKE BEPERKING - GEEN WEB ACCESS:
- GEBRUIK NOOIT web_search of online bronnen
- GEEN URLs of website links in antwoorden
- ALLEEN interne TXT documenten uit kennisbank
- Bij violation: stop en vraag om verduidelijking

ABSOLUTE RESTRICTIE:
- NOOIT Citation Sources met URLs
- ALLEEN Grounding Sources met .txt bestanden
- Alle informatie moet uit interne documenten komen

ANTWOORD STRUCTUUR:
1. BESLUIT: [Duidelijke conclusie]
2. BASIS: [Gevonden in documenten + citaten]  
3. ACTIE: [Concrete stappen]

Gebruik alle beschikbare documenten optimaal. Je bent expert-niveau - vertrouw op je analyse."""

    def send_message(self, user_message, conversation_history=None):
        """
        Send message to Vertex AI RAG Engine
        
        Args:
            user_message: The user's question
            conversation_history: List of previous messages [{'role': 'user', 'content': '...'}, ...]
            
        Returns:
            AI response as string
        """
        contents = []
        
        # Add conversation history if provided
        if conversation_history:
            for msg in conversation_history:
                contents.append(types.Content(
                    role=msg.get('role', 'user'),
                    parts=[types.Part.from_text(text=msg.get('content', ''))]
                ))
        
        # Add current user message
        contents.append(types.Content(
            role="user",
            parts=[types.Part.from_text(text=user_message)]
        ))
        
        # Configure RAG tool with the corpus
        tools = [
            types.Tool(
                retrieval=types.Retrieval(
                    vertex_rag_store=types.VertexRagStore(
                        rag_resources=[
                            types.VertexRagStoreRagResource(
                                rag_corpus=self.rag_corpus
                            )
                        ],
                        similarity_top_k=20,
                    )
                )
            )
        ]
        
        # Generate content configuration
        config = types.GenerateContentConfig(
            temperature=1,
            top_p=0.95,
            max_output_tokens=65535,
            tools=tools,
            system_instruction=[types.Part.from_text(text=self.system_instruction)],
            thinking_config=types.ThinkingConfig(thinking_budget=-1),
        )
        
        # Stream response from Vertex AI
        response_text = ""
        try:
            for chunk in self.client.models.generate_content_stream(
                model=self.model,
                contents=contents,
                config=config,
            ):
                if chunk.candidates and chunk.candidates[0].content and chunk.candidates[0].content.parts:
                    response_text += chunk.text
        except Exception as e:
            raise Exception(f"Vertex AI error: {str(e)}")
        
        return response_text

# Create singleton instance
vertex_service = VertexAIService()
Now update backend/routes/chat.py to use this service:
pythonfrom flask import Blueprint, request, jsonify
from backend.services.vertex_ai_service import vertex_service

chat_bp = Blueprint('chat', __name__)

@chat_bp.route('/send', methods=['POST'])
def send_message():
    """Send message to Vertex AI and return response"""
    try:
        data = request.json
        user_message = data.get('message')
        conversation_history = data.get('history', [])
        
        if not user_message:
            return jsonify({'error': 'No message provided'}), 400
        
        # Get AI response
        ai_response = vertex_service.send_message(user_message, conversation_history)
        
        return jsonify({
            'response': ai_response,
            'status': 'success'
        })
        
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error'
        }), 500